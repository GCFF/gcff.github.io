<!DOCTYPE html>
<html lang="en-us">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title> Neurips Wrapup Post 1 | l0.ai</title>
  <meta name="description" content="l0.ai is where I {guillermo christen} write about technology: machine learning, data and labeling, management and communication.">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="robots" content="all,follow">
  <meta name="googlebot" content="index,follow,snippet,archive">
  <meta property="og:title" content="Neurips Wrapup Post 1" />
<meta property="og:description" content="Neurips 2022 - A wrap up post #1   Neurips 2022 has just finished - and it was a great conference! It was my first proper conference since Covid, and it was so much fun. I don&rsquo;t go to Neurips to present, but rather to absorb. Over time, it has become part of my yearly calendar that I really look forward to. It&rsquo;s a chance to reconnect with what is happening at the edge of deep learning." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://l0.ai/posts/2022-12-10-neurips-2022-1/" />
<meta property="article:published_time" content="2022-12-10T18:30:00+00:00" />
<meta property="article:modified_time" content="2022-12-10T18:30:00+00:00" />

  <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Neurips Wrapup Post 1"/>
<meta name="twitter:description" content="Neurips 2022 - A wrap up post #1   Neurips 2022 has just finished - and it was a great conference! It was my first proper conference since Covid, and it was so much fun. I don&rsquo;t go to Neurips to present, but rather to absorb. Over time, it has become part of my yearly calendar that I really look forward to. It&rsquo;s a chance to reconnect with what is happening at the edge of deep learning."/>

  
  
  
  <link rel="stylesheet" href="https://l0.ai/css/style-white.css">
  
   <link rel="stylesheet" href="https://l0.ai/css/main.css"> 
  
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
  

  
<link rel="icon" type="image/png" href="https://l0.ai/images/favicon.ico" />

  
    
  
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-J7MP7KW334"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'G-J7MP7KW334');
  </script>  
</head>

<body class="max-width mx-auto px3 ltr">
  <div class="content index py4">

  <div id="header-post">
  <a id="menu-icon" href="#"><i class="fas fa-bars fa-lg"></i></a>
  <a id="menu-icon-tablet" href="#"><i class="fas fa-bars fa-lg"></i></a>
  <a id="top-icon-tablet" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');" style="display:none;"><i class="fas fa-chevron-up fa-lg"></i></a>
  <span id="menu">
    <span id="nav">
      <ul>
         
        <li><a href="/">Home</a></li>
         
        <li><a href="/posts">Writings</a></li>
         
        <li><a href="/about">About</a></li>
        
      </ul>
    </span>
    <br/>
    <span id="actions">
      <ul>
        
        <li>
          <a class="icon" href=" https://l0.ai/posts/2022-11-9-fast-diffusion/">
            <i class="fas fa-chevron-left" aria-hidden="true" onmouseover="$('#i-prev').toggle();" onmouseout="$('#i-prev').toggle();"></i>
          </a>
        </li>
        
        
        <li>
          <a class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');">
            <i class="fas fa-chevron-up" aria-hidden="true" onmouseover="$('#i-top').toggle();" onmouseout="$('#i-top').toggle();"></i>
          </a>
        </li>
        <li>
          <a class="icon" href="#">
            <i class="fas fa-share-alt" aria-hidden="true" onmouseover="$('#i-share').toggle();" onmouseout="$('#i-share').toggle();" onclick="$('#share').toggle();return false;"></i>
          </a>
        </li>
      </ul>
      <span id="i-prev" class="info" style="display:none;">Previous post</span>
      <span id="i-next" class="info" style="display:none;">Next post</span>
      <span id="i-top" class="info" style="display:none;">Back to top</span>
      <span id="i-share" class="info" style="display:none;">Share post</span>
    </span>
    <br/>
    <div id="share" style="display: none">
      
      <ul>
  
  
    
  
  
  <li>
    <a class="icon" href="http://www.facebook.com/sharer.php?u=https%3a%2f%2fl0.ai%2fposts%2f2022-12-10-neurips-2022-1%2f">
      <i class="fab fa-facebook " aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="https://twitter.com/share?url=https%3a%2f%2fl0.ai%2fposts%2f2022-12-10-neurips-2022-1%2f&text=Neurips%20Wrapup%20Post%201">
      <i class="fab fa-twitter " aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="http://www.linkedin.com/shareArticle?url=https%3a%2f%2fl0.ai%2fposts%2f2022-12-10-neurips-2022-1%2f&title=Neurips%20Wrapup%20Post%201">
      <i class="fab fa-linkedin " aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="https://pinterest.com/pin/create/bookmarklet/?url=https%3a%2f%2fl0.ai%2fposts%2f2022-12-10-neurips-2022-1%2f&is_video=false&description=Neurips%20Wrapup%20Post%201">
      <i class="fab fa-pinterest " aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="mailto:?subject=Neurips%20Wrapup%20Post%201&body=Check out this article: https%3a%2f%2fl0.ai%2fposts%2f2022-12-10-neurips-2022-1%2f">
      <i class="fas fa-envelope " aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="https://getpocket.com/save?url=https%3a%2f%2fl0.ai%2fposts%2f2022-12-10-neurips-2022-1%2f&title=Neurips%20Wrapup%20Post%201">
      <i class="fab fa-get-pocket " aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="http://reddit.com/submit?url=https%3a%2f%2fl0.ai%2fposts%2f2022-12-10-neurips-2022-1%2f&title=Neurips%20Wrapup%20Post%201">
      <i class="fab fa-reddit " aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="http://www.stumbleupon.com/submit?url=https%3a%2f%2fl0.ai%2fposts%2f2022-12-10-neurips-2022-1%2f&title=Neurips%20Wrapup%20Post%201">
      <i class="fab fa-stumbleupon " aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="http://digg.com/submit?url=https%3a%2f%2fl0.ai%2fposts%2f2022-12-10-neurips-2022-1%2f&title=Neurips%20Wrapup%20Post%201">
      <i class="fab fa-digg " aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="http://www.tumblr.com/share/link?url=https%3a%2f%2fl0.ai%2fposts%2f2022-12-10-neurips-2022-1%2f&name=Neurips%20Wrapup%20Post%201&description=Neurips%202022%20-%20A%20wrap%20up%20post%20%231%20%20%20Neurips%202022%20has%20just%20finished%20-%20and%20it%20was%20a%20great%20conference%21%20It%20was%20my%20first%20proper%20conference%20since%20Covid%2c%20and%20it%20was%20so%20much%20fun.%20I%20don%26rsquo%3bt%20go%20to%20Neurips%20to%20present%2c%20but%20rather%20to%20absorb.%20Over%20time%2c%20it%20has%20become%20part%20of%20my%20yearly%20calendar%20that%20I%20really%20look%20forward%20to.%20It%26rsquo%3bs%20a%20chance%20to%20reconnect%20with%20what%20is%20happening%20at%20the%20edge%20of%20deep%20learning.">
      <i class="fab fa-tumblr " aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="https://news.ycombinator.com/submitlink?u=https%3a%2f%2fl0.ai%2fposts%2f2022-12-10-neurips-2022-1%2f&t=Neurips%20Wrapup%20Post%201">
      <i class="fab fa-hacker-news " aria-hidden="true"></i>
    </a>
  </li>
</ul>

    </div>
    <div id="toc">
      <nav id="TableOfContents">
  <ul>
    <li><a href="#neurips-2022---a-wrap-up-post-1">Neurips 2022 - A wrap up post #1</a></li>
  </ul>
</nav>
    </div>
  </span>
</div>


  <article class="post" itemscope itemtype="http://schema.org/BlogPosting">
    <header>
      <h1 class="posttitle" itemprop="name headline">
        Neurips Wrapup Post 1
      </h1>
      <div class="meta">
        
        <div class="postdate">
          
          <time datetime="2022-12-10 18:30:00 &#43;0000 UTC" itemprop="datePublished">2022-12-10</time>
          
        </div>
        
        
        <div class="article-tag">
            <i class="fas fa-tag"></i>
            
            
            <a class="tag-link" href="/tags/ai" rel="tag">AI</a>
            
             ,  
            <a class="tag-link" href="/tags/machine-learning" rel="tag">Machine Learning</a>
            
             ,  
            <a class="tag-link" href="/tags/research" rel="tag">Research</a>
            
             ,  
            <a class="tag-link" href="/tags/neurips" rel="tag">Neurips</a>
            
        </div>
        
      </div>
    </header>

  
    <div class="content" itemprop="articleBody">
      <h2 id="neurips-2022---a-wrap-up-post-1">Neurips 2022 - A wrap up post #1</h2>
<figure>
    <img src="../sdc4.png"/> 
</figure>

<p><a href="https://nips.cc/virtual/2022/calendar">Neurips 2022</a> has just finished - and it was a great conference! It was my first proper conference since Covid, and it was so much fun. I don&rsquo;t go to Neurips to present, but rather to absorb. Over time, it has become part of my yearly calendar that I really look forward to. It&rsquo;s a chance to reconnect with what is happening at the edge of deep learning.</p>
<p>There was so much interesting work on display at the conference, and here are some initial highlights from the poster sessions. I have so many notes that I suspect there will be one or two more posts in the future.</p>
<p><strong>Highlights</strong></p>
<ul>
<li>
<p><a href="https://openreview.net/forum?id=08Yk-n5l2Al">Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding</a> - This is probably the most noteworthy paper in the conference - it&rsquo;s SOTA results on image generation which used a pretrained large language model (LLM) were the harbinger of a whole slew of incredible results in generative modeling using diffusion models.</p>
</li>
<li>
<p><a href="https://openreview.net/pdf?id=0RTJcuvHtIu">Flexible Diffusion Modeling of Long Videos</a> - As soon as the first DALLE image generation results came out, and certainly after stable diffusion, video has been the next fronteir both users and researchers have been waiting to be breached. Up to now, snipets of a few frames with some consistency were possible. Three works at Neurips this yeah show significant progress, and this is one of them. By flexibly choosing which frames to condition on <em>and</em> which frames to generate, this paper proposes a method that makes coherent long video (semantically and temporally) possible. This was also the coolest poster presentation as it included <strong>8</strong> ipads hung onto the poster! The other two works were <a href="https://arxiv.org/pdf/2207.13751">GAUDI: A Neural Architect for Immersive 3D Scene Generation</a> (presented super well Miguel Angle Bautista) and <a href="https://openreview.net/pdf?id=VnAwNNJiwDb">Generating Long Videos of Dynamic Scenes</a></p>
</li>
<li>
<p><a href="https://arxiv.org/pdf/2203.02155">Training language models to follow instructions with human feedback</a> - Large Language Models are everywhere nowadays and this work will only make them more popular. InstructGPT is no doubt part of the magic of ChatGPT. Re-inforcement learning from human feedback is applied to a Large Language Model to algin the results of the language model to human preferences. Specifically, three steps happen: <strong>1.</strong> in supervised pretraining demostrators take a prompt and show what should have been generated, <strong>2.</strong> a reward model is trained by having labelers rank different generations by the finetuned model from step 1, <strong>3.</strong> the reward model is used in an RL setting (policy gradient optimization) to further fine-tune the language model to align with human preferences. This work has the potential to have a significant impact and could be the basis for using language models in industry applications.</p>
</li>
</ul>
<p><strong>Interesting:</strong></p>
<ul>
<li>
<p>Fine tunning on human preferences, a fascinating <a href="https://openreview.net/pdf?id=G5ADoRKiTyJ">paper</a> and <a href="https://neurips.cc/media/PosterPDFs/NeurIPS%202022/53005.png?t=1669138105.9691656">poster</a> from DeepMind.  It explores how using a large language model you might model (find) agreement within humans with diverse preferences, even better than if humans tried to find this alignment. This work has applicabilty on community moderation</p>
</li>
<li>
<p><a href="https://openreview.net/forum?id=02dbnEbEFn">Decoupled Context Processing for Context Augmented Language Modeling</a>. This paper proposes a simple but efficient way of retriving context for, context augmented tranformers. Specifically, decoupling the retrieval of context during inference time and by doing so, enabling the pre-computation of that context.</p>
</li>
<li>
<p><a href="https://openreview.net/pdf?id=_3ELRdg2sgI">STaR: Bootstrapping Reasoning With Reasoning</a> - There was plenty of work exploring chain of thought agumentations: different flavour of providing of generating an explanation or rationale for a given prediction, or training or fine-tunning with <em>scratch-pads</em> that include the <em>chain of thought</em> to get to an answer.  This paper introduces a way to boot-strap rationales directly from a large language model. They <em>few-shot prompt a large language model to self-generate rationales and refine the modelâ€™s ability further by fine-tuning on those rationales that lead to correct answers.</em></p>
</li>
<li>
<p><a href="https://openreview.net/pdf?id=uloenYmLCAo">Block recurrent transformers</a> and <a href="https://openreview.net/pdf?id=1beC9_dmOQ0">Jump Self Attention</a> - two interesting posters. Block recurrence allows models to capture  relationships in input that is much longer than what sequence length allows for in current transformers. It does this by running sliding window attention over blocks of input <em>and state vectors</em>. State vectors are calcualted over the last segment of blocks (just like old RNNs).</p>
</li>
<li>
<p><a href="https://github.com/IBM/UQ360">UQ360</a> - An uncertainty quantification toolbox presented by IBM. Uncertainty quantification can be either intrinsic, <em>a model creates some for of uncertainty measure</em> (e.g. gaussian mixture models) or extrinsic, a method external to the modeling procedure estimates uncertainty post-hoc. This workshop talk and the package described at the end of it, provded a toolbox for providing uncertainty quantification to most models. I&rsquo;m keen on learning much more about this, as providing an uncertainty measure <em>as a key deliverable</em> of any ML work should become standard and it is far from being the case right now</p>
</li>
<li>
<p><a href="https://openreview.net/pdf?id=yhlMZ3iR7Pu">Diffusion Models as Plug-and-Play Priors</a> - Really interesting work that advances conditioning diffusion models by trating the diffusion model as a module that <em>knows about</em> priors. There are some neat examples in image segmentation but this is a highlight for me because of what I think might be it&rsquo;s applicability in making learned distributions (over types of image space for instance) usable in a modular way</p>
</li>
<li>
<p><a href="https://openreview.net/forum?id=fT9W53lLxNS">SAVi++: Towards End-to-End Object-Centric Learning from Real-World Videos</a> - Building on Slot Attention, describes work to model object segmentation and tracking without supervision (ground truth or labeled segmentation maps) for Video. The core premise is the few slot attention buckets fight to explain each pixel in each frame in a video. This competiton leads to salient object, especially over time</p>
</li>
</ul>
<p><strong>Other interesting work:</strong></p>
<ul>
<li><a href="https://openreview.net/pdf?id=0Oy3PiA-aDp">Generalised Mutual Information for Discriminative Clustering</a></li>
<li><a href="https://openreview.net/forum?id=ePhEbo039l">Focal Modulation Networks</a> - a clever way to take the intution of focal attention to make cheaper transfoermer based vision models</li>
<li><strong>Work exploring cheaper inference</strong>: <a href="https://arxiv.org/abs/2110.02861">8 bit quantisation</a> (<a href="https://github.com/TimDettmers/bitsandbytes">code</a>), 8bit quantisation <a href="https://openreview.net/forum?id=dXiGWqBoxaD">at scale</a> DeepSpeed, Flash [Attention](<a href="https://neurips.cc/media/PosterPDFs/NeurIPS">https://neurips.cc/media/PosterPDFs/NeurIPS</a> 2022/54008.png?t=1669572827.0747266), <a href="https://openreview.net/forum?id=wYgRIJ-oK6M">Binarised quantisation</a></li>
</ul>

    </div>
  </article>

  
  





  <div id="footer-post-container">
  <div id="footer-post">

    <div id="nav-footer" style="display: none">
      <ul>
         
          <li><a href="/">Home</a></li>
         
          <li><a href="/posts">Writings</a></li>
         
          <li><a href="/about">About</a></li>
        
      </ul>
    </div>

    <div id="toc-footer" style="display: none">
      <nav id="TableOfContents">
  <ul>
    <li><a href="#neurips-2022---a-wrap-up-post-1">Neurips 2022 - A wrap up post #1</a></li>
  </ul>
</nav>
    </div>

    <div id="share-footer" style="display: none">
      
      <ul>
  
  
    
  
  
  <li>
    <a class="icon" href="http://www.facebook.com/sharer.php?u=https%3a%2f%2fl0.ai%2fposts%2f2022-12-10-neurips-2022-1%2f">
      <i class="fab fa-facebook fa-lg" aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="https://twitter.com/share?url=https%3a%2f%2fl0.ai%2fposts%2f2022-12-10-neurips-2022-1%2f&text=Neurips%20Wrapup%20Post%201">
      <i class="fab fa-twitter fa-lg" aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="http://www.linkedin.com/shareArticle?url=https%3a%2f%2fl0.ai%2fposts%2f2022-12-10-neurips-2022-1%2f&title=Neurips%20Wrapup%20Post%201">
      <i class="fab fa-linkedin fa-lg" aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="https://pinterest.com/pin/create/bookmarklet/?url=https%3a%2f%2fl0.ai%2fposts%2f2022-12-10-neurips-2022-1%2f&is_video=false&description=Neurips%20Wrapup%20Post%201">
      <i class="fab fa-pinterest fa-lg" aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="mailto:?subject=Neurips%20Wrapup%20Post%201&body=Check out this article: https%3a%2f%2fl0.ai%2fposts%2f2022-12-10-neurips-2022-1%2f">
      <i class="fas fa-envelope fa-lg" aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="https://getpocket.com/save?url=https%3a%2f%2fl0.ai%2fposts%2f2022-12-10-neurips-2022-1%2f&title=Neurips%20Wrapup%20Post%201">
      <i class="fab fa-get-pocket fa-lg" aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="http://reddit.com/submit?url=https%3a%2f%2fl0.ai%2fposts%2f2022-12-10-neurips-2022-1%2f&title=Neurips%20Wrapup%20Post%201">
      <i class="fab fa-reddit fa-lg" aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="http://www.stumbleupon.com/submit?url=https%3a%2f%2fl0.ai%2fposts%2f2022-12-10-neurips-2022-1%2f&title=Neurips%20Wrapup%20Post%201">
      <i class="fab fa-stumbleupon fa-lg" aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="http://digg.com/submit?url=https%3a%2f%2fl0.ai%2fposts%2f2022-12-10-neurips-2022-1%2f&title=Neurips%20Wrapup%20Post%201">
      <i class="fab fa-digg fa-lg" aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="http://www.tumblr.com/share/link?url=https%3a%2f%2fl0.ai%2fposts%2f2022-12-10-neurips-2022-1%2f&name=Neurips%20Wrapup%20Post%201&description=Neurips%202022%20-%20A%20wrap%20up%20post%20%231%20%20%20Neurips%202022%20has%20just%20finished%20-%20and%20it%20was%20a%20great%20conference%21%20It%20was%20my%20first%20proper%20conference%20since%20Covid%2c%20and%20it%20was%20so%20much%20fun.%20I%20don%26rsquo%3bt%20go%20to%20Neurips%20to%20present%2c%20but%20rather%20to%20absorb.%20Over%20time%2c%20it%20has%20become%20part%20of%20my%20yearly%20calendar%20that%20I%20really%20look%20forward%20to.%20It%26rsquo%3bs%20a%20chance%20to%20reconnect%20with%20what%20is%20happening%20at%20the%20edge%20of%20deep%20learning.">
      <i class="fab fa-tumblr fa-lg" aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="https://news.ycombinator.com/submitlink?u=https%3a%2f%2fl0.ai%2fposts%2f2022-12-10-neurips-2022-1%2f&t=Neurips%20Wrapup%20Post%201">
      <i class="fab fa-hacker-news fa-lg" aria-hidden="true"></i>
    </a>
  </li>
</ul>

    </div>

    <div id="actions-footer">
      
        <a id="menu" class="icon" href="#" onclick="$('#nav-footer').toggle();return false;">
          <i class="fas fa-bars fa-lg" aria-hidden="true"></i> Menu</a>
        <a id="toc" class="icon" href="#" onclick="$('#toc-footer').toggle();return false;">
          <i class="fas fa-list fa-lg" aria-hidden="true"></i> TOC</a>
        <a id="share" class="icon" href="#" onclick="$('#share-footer').toggle();return false;">
          <i class="fas fa-share-alt fa-lg" aria-hidden="true"></i> share</a>
        <a id="top" style="display:none" class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');">
          <i class="fas fa-chevron-up fa-lg" aria-hidden="true"></i> Top</a>
    </div>

  </div>
</div>


  <footer id="footer">
  <div class="footer-left">
    Copyright  &copy; 2022  l0.ai 
  </div>
  <div class="footer-right">
    <nav>
      <ul>
         
        <li><a href="/">Home</a></li>
         
        <li><a href="/posts">Writings</a></li>
         
        <li><a href="/about">About</a></li>
        
      </ul>
    </nav>
  </div>
</footer>


  </div>
</body>

<link rel="stylesheet" href=/lib/font-awesome/css/all.min.css>
<script src=/lib/jquery/jquery.min.js></script>
<script src=/js/main.js></script>



</html>
