<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>dreambooth on l0.ai</title>
    <link>https://l0.ai/tags/dreambooth/</link>
    <description>Recent content in dreambooth on l0.ai</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 06 Nov 2022 09:25:06 +0000</lastBuildDate>
    
	<atom:link href="https://l0.ai/tags/dreambooth/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Stable Diffusion Experiment 3</title>
      <link>https://l0.ai/posts/2022-11-6-stable-diffusion-3/</link>
      <pubDate>Sun, 06 Nov 2022 09:25:06 +0000</pubDate>
      
      <guid>https://l0.ai/posts/2022-11-6-stable-diffusion-3/</guid>
      <description>Imagining myself in new images Textual Inversion In an earlier post I referenced work on Textual Inversion that allows new concepts to be added to the Stable Diffusion model. Textual inversion trains a new set of embeddings that can be used to generate a new object or style you provide through pictures.       I used textual inversion to generate some portraits of our pup, though this worked well and generated some beautiful images it wasn&amp;rsquo;t exactly like our dog.</description>
    </item>
    
  </channel>
</rss>